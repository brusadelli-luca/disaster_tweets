{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9167ac13",
   "metadata": {},
   "source": [
    "# Eye of the Emergency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fd82f9",
   "metadata": {},
   "source": [
    "## Libraries and dataset import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9486461",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\utile\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\utile\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\utile\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\utile\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# \n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import string\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# ML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1db272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_tweets.csv')\n",
    "test_df = pd.read_csv('test_tweets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9a49e5",
   "metadata": {},
   "source": [
    "## Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1460ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_count = pd.DataFrame(pd.value_counts(train_df.text))\n",
    "unique_count = unique_count.reset_index()\n",
    "unique_count.columns = ['text', 'count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e58be70b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#unique_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee09db9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_unique = pd.DataFrame(train_df.text.unique(), columns = ['text'])\n",
    "#train_df_unique.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17533f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_unique = train_df_unique.merge(unique_count)\n",
    "#train_df_unique.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9acccc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_count = train_df.merge(unique_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19e17a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b09cfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = pd.DataFrame([len(txt) for txt in train_df.text], columns = ['len_text'])\n",
    "#lg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d093c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_len = pd.concat([train_df_count, lg], axis = 1)\n",
    "#train_df_len.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab696116",
   "metadata": {},
   "source": [
    "### Location Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e201b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_location = pd.DataFrame([int(type(ct)==str) for ct in train_df_len.location], columns=['location_enc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ea22e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>count</th>\n",
       "      <th>len_text</th>\n",
       "      <th>location_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  count  len_text  location_enc  \n",
       "0       1      1        69             0  \n",
       "1       1      1        38             0  \n",
       "2       1      1       133             0  \n",
       "3       1      1        65             0  \n",
       "4       1      1        88             0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_location = pd.concat([train_df_len, encode_location], axis=1)\n",
    "train_df_location.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d725ccd1",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9869a306",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = pd.read_csv('stopwords.txt', header = None)\n",
    "stopwords.columns=['words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a20b5ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = [wrd for wrd in stopwords.words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "428de7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords.append('http')\n",
    "stopwords.append('https')\n",
    "stopwords.append('Û_')\n",
    "stopwords.append('amp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6b02e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [txt for txt in train_df_location.text]\n",
    "#text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4822c6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_lst_str = ' '.join(map(str, text))\n",
    "#my_lst_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "719ec712",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_0 = [txt for txt in train_df_location.text[train_df_location.target == 0]]\n",
    "text_1 = [txt for txt in train_df_location.text[train_df_location.target == 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e51937c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_lst_str_0 = ' '.join(map(str, text_0))\n",
    "my_lst_str_1 = ' '.join(map(str, text_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db5b4411",
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_lst_str_0\n",
    "#my_lst_str_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2613a797",
   "metadata": {},
   "source": [
    "## NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de224110",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df_location.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b6cc367",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = train_df_location.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "caf78558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text cleaning\n",
    "\n",
    "def text_processing(text):\n",
    "     #Charger les stop-words en anglais\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # Initialiser le lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # Appliquer la tokenisation à tous les textes\n",
    "    tokens = word_tokenize(text.lower())\n",
    "\n",
    "    # Supprimer les ponctuations\n",
    "    tokens = [word for word in tokens if word not in string.punctuation]\n",
    "    \n",
    "\n",
    "    # Supprimer les stop-words\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "\n",
    "    # Appliquer la lemmatisation à tous les tokens\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    \n",
    "    tokens = ' '.join(tokens)\n",
    "    return tokens\n",
    "    \n",
    "\n",
    "# Charger l'ensemble de données\n",
    "#df = pd.read_csv('votre_fichier.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d248f87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquer la fonction Cleanup à tous les textes dans la colonne \"text\"\n",
    "df2['text_process'] = df['text'].apply(text_processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7694f7c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>count</th>\n",
       "      <th>len_text</th>\n",
       "      <th>location_enc</th>\n",
       "      <th>text_process</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>deed reason earthquake may allah forgive u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "      <td>0</td>\n",
       "      <td>resident asked 'shelter place notified officer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>13,000 people receive wildfire evacuation orde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>got sent photo ruby alaska smoke wildfire pour...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  count  len_text  location_enc  \\\n",
       "0       1      1        69             0   \n",
       "1       1      1        38             0   \n",
       "2       1      1       133             0   \n",
       "3       1      1        65             0   \n",
       "4       1      1        88             0   \n",
       "\n",
       "                                        text_process  \n",
       "0         deed reason earthquake may allah forgive u  \n",
       "1              forest fire near la ronge sask canada  \n",
       "2  resident asked 'shelter place notified officer...  \n",
       "3  13,000 people receive wildfire evacuation orde...  \n",
       "4  got sent photo ruby alaska smoke wildfire pour...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af3e7f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deed reason earthquake may allah forgive u'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.text_process[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2358d775",
   "metadata": {},
   "source": [
    "## ML : SVM avec sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "37890d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df2['text_process'], df2['target'], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81a59876",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7eda1ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instanciation\n",
    "model_SVC = SVC(kernel = 'linear', gamma = 'scale', shrinking = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aad76353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', shrinking=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training\n",
    "model_SVC.fit(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba6eda88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7905449770190414"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calcul de la précision\n",
    "model_SVC.score(X_test_vec, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6984449d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prédiction\n",
    "pred = pd.Series([\"Help me, my house is on fire and all the forest is burning\"])\n",
    "X_test_vec = vectorizer.transform(pred)\n",
    "prediction = model_SVC.predict(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "02007165",
   "metadata": {},
   "outputs": [],
   "source": [
    "#affichage des résultats\n",
    "resultat = \"Résultat : \"\n",
    "if prediction[0] == 0:\n",
    "    resultat = resultat + \"NO DISASTER\"\n",
    "if prediction[0] == 1:\n",
    "    resultat = resultat + \"DISASTER\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aef6ce4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Résultat : DISASTER'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1987f0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prédiction\n",
    "pred = pd.Series([\"Hello\"])\n",
    "X_test_vec = vectorizer.transform(pred)\n",
    "prediction = model_SVC.predict(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "39313256",
   "metadata": {},
   "outputs": [],
   "source": [
    "#affichage des résultats\n",
    "resultat = \"Résultat : \"\n",
    "if prediction[0] == 0:\n",
    "    resultat = resultat + \"NO DISASTER\"\n",
    "if prediction[0] == 1:\n",
    "    resultat = resultat + \"DISASTER\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3a123e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Résultat : NO DISASTER'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98216794",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
